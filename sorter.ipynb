{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Function to return softmax\n",
    "    '''\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.array(softmax([1,2,3])) != np.array([0.09003057, 0.24472847, 0.66524096])).all(), \"Softmax result not correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(self, prob, target):\n",
    "    '''\n",
    "    Calculate cross-entrpy loss\n",
    "    '''\n",
    "    return -np.sum(np.log(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, max_n, hidden_layers):\n",
    "        '''\n",
    "        W is weight\n",
    "        Whh weight at previous hidden state\n",
    "        Whx weight at current input state\n",
    "        Why weight at the output state\n",
    "\n",
    "        Formula for the current state: h_t = f(h_{t-1}, x_t) where \n",
    "\n",
    "        '''\n",
    "        self.max_n = max_n\n",
    "        self.hidden_layers = hidden_layers\n",
    "\n",
    "        self.Wxh: np.ndarray = 0.01 * np.random.randn(hidden_layers, max_n + 1)\n",
    "        self.Whh: np.ndarray = 0.01 * np.random.randn(hidden_layers, hidden_layers)\n",
    "        self.Why: np.ndarraynp.ndarray = 0.01 * np.random.randn(max_n, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(self, x_input, y, size):\n",
    "    \n",
    "    hidden_states = []\n",
    "    hidden_states.append(np.zeros((self.hidden_layers, 1)))    \n",
    "    \n",
    "    probs = []\n",
    "    prediction = np.zeros(size)\n",
    "    loss = 0\n",
    "    \n",
    "    for pos in range(size):\n",
    "        x_input[self.max_n] = pos\n",
    "        hidden = np.tanh(np.dot(self.Wxh, x_input) + np.dot(self .Whh, hidden_states[-1]))\n",
    "        hidden_states.append(hidden)\n",
    "\n",
    "        output = np.dot(self.Why, hidden)\n",
    "        prob = softmax(output)\n",
    "        probs.append(prob)\n",
    "\n",
    "        loss += -np.log(prob[y[pos],0]) \n",
    "\n",
    "        prediction[pos] = np.argmax(prob)\n",
    "            \n",
    "    return prediction, hidden_states, probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def rnn_backward(self, x_input, y, size, hidden_states, probs):\n",
    "\n",
    "        dWxh = np.zeros_like(self.Wxh)\n",
    "        dWhh = np.zeros_like(self.Whh)\n",
    "        dWhy = np.zeros_like(self.Why)\n",
    "        dhnext = np.zeros_like(hidden_states[0])\n",
    "        \n",
    "        for pos in reversed(range(size)):\n",
    "            X[self.max_n] = pos\n",
    "            dy = np.copy(probs[pos])\n",
    "            dy[y[pos]] -= 1 \n",
    "\n",
    "            dWhy += np.dot(dy, hidden_states[pos].T)\n",
    "            \n",
    "            dh = np.dot(self.Why.T, dy) + dhnext \n",
    "            dhraw = (1 - hidden_states[pos] * hidden_states[pos]) * dh \n",
    "            \n",
    "            dWxh += np.dot(dhraw, X.T)\n",
    "            dWhh += np.dot(dhraw, hidden_states[pos-1].T)\n",
    "            \n",
    "            dhnext = np.dot(self.Whh.T, dhraw)\n",
    "\n",
    "            \n",
    "        return dWxh, dWhh, dWhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural networks take input as vectors so we have to convert integers to vectors using one-hot encoding\n",
    "# This function will encode a given integer sequence into RNN compatible format (one-hot representation)\n",
    "\n",
    "def encode(x_input, max_n):\n",
    "    one_hot = np.zeros((max_n + 1, 1))\n",
    "    one_hot[x_input, :] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levendistance(a: np.ndarray, b: np.ndarray) -> int:\n",
    "    n = len(a) \n",
    "    m = len(b)\n",
    "    if n > m:\n",
    "        a, b = b, a\n",
    "        n, m = m, n\n",
    "\n",
    "    current_row = range(n + 1)\n",
    "    for i in range(1, m + 1):\n",
    "        previous_row, current_row = current_row, [i] + [0] * n\n",
    "        for j in range(1, n + 1):\n",
    "            add = previous_row[j] + 1\n",
    "            delete = current_row[j - 1] + 1\n",
    "            change = previous_row[j - 1] \n",
    "            if a[j - 1] != b[i - 1]:\n",
    "                change += 1\n",
    "            current_row[j] = min(add, delete, change)\n",
    "\n",
    "    return current_row[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self, max_examples, learning_rate, max_seq_len, lr_lambda = 0.4, lr_reduce_rate = 500, info_rate = 100):\n",
    "        \n",
    "        distances = 0\n",
    "        dist_list = []\n",
    "        \n",
    "        for i in range(max_examples):\n",
    "            sequence_size = max_seq_len\n",
    "            \n",
    "            X_input = np.random.randint(self.max_n, size=sequence_size)\n",
    "            y = np.sort(X_input)\n",
    "\n",
    "            one_hot = self.encode(max_n)\n",
    "        \n",
    "            prediction, hidden_states, probs, loss = self.rnn_forward(one_hot, y, sequence_size)\n",
    "                \n",
    "            distances += levendistance(prediction, y)\n",
    "            \n",
    "            dWxh, dWhh, dWhy = self.backward(one_hot, y, sequence_size, \n",
    "                                        hidden_states, probs)\n",
    "            \n",
    "            self.Wxh -= learning_rate * dWxh\n",
    "            self.Whh -= learning_rate * dWhh\n",
    "            self.Why -= learning_rate * dWhy\n",
    "            \n",
    "            if (i + 1) % lr_reduce_rate == 0:\n",
    "                learning_rate *= lr_lambda\n",
    "\n",
    "            if (i + 1) % info_rate == 0:\n",
    "                average_distance = float(distances) / info_rate\n",
    "                dist_list.append(average_distance)\n",
    "                print('Levenshtein distance for last {} sequences = {}'.format(info_rate, average_distance))\n",
    "                \n",
    "        return dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_generated = 10\n",
    "seq_len = 10\n",
    "X_input = np.random.randint(max_numbers, size=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3, 6, 2, 1, 5, 9, 4, 9, 9, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X, seq_len, vocab_size):\n",
    "    x = np.zeros((len(X), seq_len, vocab_size), dtype=np.float32)\n",
    "    for ind, batch in enumerate(X):\n",
    "            x[ind, batch[0], batch[1]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-697c5a7ebb1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_number_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-878b9b6c5608>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(X, seq_len, vocab_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "encode(X_input, seq_len, max_number_generated)"
   ]
  },
  {
   "source": [
    "The hidden dimension is basically the number of nodes in each layer "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 50\n",
    "modelRnn = RNN(max_number_generated, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3 6 2 1 5 9 4 9 9 2] = X\n[1 2 2 3 4 5 6 9 9 9] = Target\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ecf7e7e6c60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} = X'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} = Target'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} = Before training prediction'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print('{} = X'.format(X_input))\n",
    "print('{} = Target'.format(np.sort(X_input)))\n",
    "print('{} = Before training prediction'.format(modelRNN.predict(X_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}